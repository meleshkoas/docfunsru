### Генеративные предобученные трансформеры (GPT)

- Генеративные
- Предобученные
- Трансформеры

### Трансформеры

- Семейство алгоритмов, на которором строятся все современные нейронки
- Не только для text-to-text, для чего угодно
- Придуманы Google для перевода текста с одного языка на другой

### Текстовые трансформеры

1. Берут текст (возможно, что-то еще тоже)
2. Угадывают следующее слово
3. См. п. 1

**Мама мыла ____**

    86 % ... раму
    12 % ... Рому
    3 %  ... папу

### Кодирование и токены

    Hello World!            <-- Запрос

    `Hello`, `World`, `!`   <-- Разбивка

    `13225`, `5922`, `0`    <-- Токенизация

    ???                     <-- "Размышление"

    `12194`, `0`            <-- Вывод

    `Hi`, `!`               <-- Ответ

### Токенизация

    мама мыла раму                      <-- Ввод

    `м`, `а`, `ы`, `л`, `р`, `у`, `_`   <-- Разбивка 0

    `ма`, `мы`, `ла`, `ра`, `му`, `а_`  <-- Разбивка 1

    `мама`, `мыла`, `раму`              <-- Разбивка 2.1

    `ма`, `мыл`, `рам`                  <-- Разбивка 2.2

В GPT3 словарь составляет 50 257 токенов.

Для не-текстовых моделей токены состоят из чего-то другого.

### Векторизация (Embedding)

                      словарь
                    /         \
    `мама` ->   [8.5, 6.2, 8.1 ...]
    `мыла` ->   [6.3, 2.6, 3.3 ...]
    `раму` ->   [1.1, 9.2, 0.1 ...]

Вектора для похожих по смыслу слов будут похожими.

    `мать` ->   [8.3, 6.4, 8.1 ...]
    `чистила` > [6.0, 3.0, 3.0 ...]
    `окно` ->   [1.3, 9.1, 0.2 ...]

Вектор токена в GPT3 -- 12,228 чисел в формате fp16

### Блок внимания

    `мама` ->   [8.5, 6.2, 8.1 ...]
                  \    /    |
    `мыла` ->   [6.3, 2.6, 3.3 ...]
                  /    /    \
    `раму` ->   [1.1, 9.2, 0.1 ...]

На этом этапе смежные векторы донастраиваются друг под друга, чтобы уловить нюансы.

(Мама) **мыла** (раму) != (я уронил кусок) **мыла**

### Блок мультиуровнего восприятия

Каждый вектор проходит через серию вопросов, например:

- Это слово на русском?
- Это существительное?
- Это человек?
- Это количество?
- Это часть цитаты?
- Это часть неправды?
- ...

В зависимости от ответа элементы вектора могут корректироваться.

### Повторение предыдущих шагов

- Блок внимания
- Блок мультиуровнего восприятия
- Блок внимания
- Блок мультиуровнего восприятия
- Блок внимания
- Блок мультиуровнего восприятия
- ...

В реузльтате вектора, построенные из одних слов, могут под капотом начинать означать совершенно другие вещи.

### Перемножение и девекторизация

Наконец, на основании последнего вектора в матрице вычисляется следующий. Он сверяется со словарем, из которого выбираются наиболее похожие вектора. Применяются дополнительные настройки фильтрации и температура.

**Мама мыла ____**

    86 % ... раму
    12 % ... Рому
    3 %  ... папу

### Системный промпт

Позволяет подстегнуть генерацию в нужном направлении.

```
System:
Ты специалист по учебникам русского языка для начальних классов. Ответь на последний запрос пользователя. 

User:
Что мыла мама?

Assistant:
_____
```